{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization and Table Builder for Operational DSM2 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Jupyter Notebook it works by clicking on a cell and pressing shift+enter to execute the code in the cell. All the code in this notebook should be execute to produce outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported libraries required for running this notebook\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import panel as pn\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import geopandas as gpd\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.stats import ks_2samp\n",
    "gv.extension(\"bokeh\", \"plotly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER REQUIRE INPUTS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below contains variables for all the required user inputs for running this notebook from one week to the next. These user inputs should be modified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Required Inputs\n",
    "# 0.) Working directory for the DSM2 study\n",
    "primary_work_dir = r\"\"\n",
    "# 1.) Channels Geojson Location, default = \".\\channels.geojson\"\n",
    "channels_pathname = \".\\channels.geojson\"\n",
    "# 2.) Output runid folder from the post-processing tool\n",
    "# should contain VarKS.csv and VarTotal.csv\n",
    "runid_output_folder = \"\"\n",
    "# 3.) Action start date, format YYYY-MM-DD\n",
    "action_start = \"\"\n",
    "# 4.) Action end date, format YYYY-MM-DD\n",
    "action_end = \"\"\n",
    "# 5.) *.html Panel Visualization output file name\n",
    "panel_html_vis_output_filename = \"dsm2.html\"\n",
    "# 6.) Output folder for the *.png extend graphs\n",
    "graph_png_output_foldername = \"extend_graphs\"\n",
    "# 7.) Output folder for the *.csv tables\n",
    "tables_csv_output_foldername = \"extend_tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runid_output_dir = os.path.join(primary_work_dir, runid_output_folder)\n",
    "panel_html_vis_output_pathname = os.path.join(primary_work_dir,\n",
    "                                              panel_html_vis_output_filename)\n",
    "graph_png_output_pathname = os.path.join(primary_work_dir,\n",
    "                                         graph_png_output_foldername)\n",
    "tables_csv_output_pathname = os.path.join(primary_work_dir,\n",
    "                                          tables_csv_output_foldername)\n",
    "if not os.path.exists(graph_png_output_pathname):\n",
    "    os.mkdir(graph_png_output_pathname)\n",
    "if not os.path.exists(tables_csv_output_pathname):\n",
    "    os.mkdir(tables_csv_output_pathname)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting here code is executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell does the following:  \n",
    "1.) Read-in the channels geojson file as a geopandas dataframe.  \n",
    "2.) Read-in VarKS.csv as a pandas dataframe from runid_output_dir.  \n",
    "3.) Read-in VarTotal.csv as a pandas dataframe from runid_output_dir.  \n",
    "4.) Convert the VarTotal dataframe column 'datetime' as a pandas datetime type.  \n",
    "5.) Select VarTotal dataframe based on the timeframe from action_start to action_end.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = gpd.read_file(channels_pathname)\n",
    "varks_df = pd.read_csv(os.path.join(runid_output_dir, \"VarKS.csv\"),\n",
    "                       sep=\",\", infer_datetime_format=True,\n",
    "                       parse_dates=True, header=0, index_col=0)\n",
    "vartotal_df = pd.read_csv(os.path.join(runid_output_dir, \"VarTotal.csv\"),\n",
    "                          sep=\",\", infer_datetime_format=True,\n",
    "                          parse_dates=True, header=0, index_col=0)\n",
    "vartotal_df[\"datetime\"] = pd.to_datetime(vartotal_df[\"datetime\"])\n",
    "select_datetime_range = pd.date_range(start=action_start,\n",
    "                                      end=action_end, freq=\"15min\")\n",
    "vartotal_df = vartotal_df.loc[vartotal_df[\"datetime\"]\n",
    "                              .isin(select_datetime_range)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays the outputs from above for the user to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(channels)\n",
    "display(varks_df)\n",
    "display(vartotal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the identifiers for each scenario and variable pair.  \n",
    "For example \"OMR-5000 FLOW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ks_options = []\n",
    "for scenario in varks_df[\"scenario1\"].unique():\n",
    "    for variable in varks_df[\"variable\"].unique():\n",
    "        map_ks_options.append(\"{} {}\".format(scenario, variable))\n",
    "test_map_value = map_ks_options[0]\n",
    "display(map_ks_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a list for the variable identifiers and the important channels from the DSM2 analysis. The full important channels are set as channel_lst, while the most important channels are set as critical_channel_lst. The channels were identified by BDO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_lst = [\"FLOW\", \"VEL\"]\n",
    "channel_lst = [6, 21, 24, 49, 54, 81, 94, 107, 117, 124, 148, 160,\n",
    "               173, 214, 227, 310, 421, 422, 423, 434]\n",
    "critical_channel_lst = [6, 21, 49, 81, 94, 107, 124, 148, 160, 434]\n",
    "channel_lst = [int(x) for x in channel_lst]\n",
    "critical_channel_lst = [int(x) for x in critical_channel_lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the two dropdown widgets for the *.html* Panel Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dropdown = pn.widgets.Select(name=\"variable_dropdown\",\n",
    "                                      options=variable_lst)\n",
    "channel_dropdown = pn.widgets.Select(name=\"channel_dropdown\",\n",
    "                                     options=channel_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for building each map in the *.html* Panel Visualization.  \n",
    "This function is called by the Panel Builder for each map based on the map_ks_options variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_map(value):\n",
    "    global channels\n",
    "    global varks_df\n",
    "    ichannels = channels.copy()\n",
    "    base_map = gv.tile_sources.CartoLight.opts(width=950, height=600)\n",
    "    select_ks_stat = varks_df.loc[(varks_df[\"scenario1\"] == \n",
    "                                   value.split(\" \")[0]) &\n",
    "                                  (varks_df['variable'] == \n",
    "                                   value.split(\" \")[1])]\n",
    "    select_ks_stat = select_ks_stat[[\"channel\", \"ks_stat\"]].set_index('channel')\n",
    "    input_df = ichannels.set_index(\"channel_nu\").join(select_ks_stat)\n",
    "    input_df[[\"ks_stat\"]] = input_df[[\"ks_stat\"]].fillna(0)\n",
    "    delta = gv.Contours(input_df,\n",
    "                        vdims=[\"ks_stat\", \"channel_nu\"]).opts(cmap=\"turbo_r\",\n",
    "                                                              tools=[\"hover\"],\n",
    "                                                              width=600,\n",
    "                                                              height=600,\n",
    "                                                              line_width=3,\n",
    "                                                              colorbar=True,\n",
    "                                                              show_legend=False,\n",
    "                                                              clim=(0, 1))\n",
    "    total_map = base_map*delta\n",
    "    return total_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for building each plotly graph in the *.html* Panel Visualization.  \n",
    "This function is called by the Panel Builder for each variable, channel pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mapgraph(variable, channel):\n",
    "    global vartotal_df\n",
    "    global varks_df\n",
    "    df = vartotal_df\n",
    "    df_ks = varks_df\n",
    "    DEFAULT_PLOTLY_COLORS=['rgb(31, 119, 180)', 'rgb(255, 127, 14)',\n",
    "                           'rgb(188, 189, 34)', 'rgb(140, 86, 75)',\n",
    "                           'rgb(148, 103, 189)', 'rgb(127, 127, 127)',\n",
    "                           'rgb(227, 119, 194)', 'rgb(23, 190, 207)',\n",
    "                           'rgb(44, 160, 44)', 'rgb(214, 39, 40)']    \n",
    "    df_select = df.loc[(df[\"variable\"] == variable) &\n",
    "                       (df[\"channel\"] == channel)\n",
    "                       ]\n",
    "    \n",
    "    trace_lst = []\n",
    "    ks_lst = []\n",
    "    for indx, scenario in enumerate(df_select[\"scenario\"].unique()):\n",
    "        data_arr = (df_select\n",
    "                    .loc[(df_select[\"scenario\"] == scenario)][\"value\"]\n",
    "                    .to_numpy(dtype=np.float32))\n",
    "        ecdf_obj = ECDF(data_arr)\n",
    "        trace = go.Scatter(x=ecdf_obj.x, y=ecdf_obj.y,\n",
    "                           mode=\"lines\", name=scenario,\n",
    "                           line=dict(color=DEFAULT_PLOTLY_COLORS[indx]))\n",
    "        trace_lst.append(trace)\n",
    "        if not \"Baseline\" in scenario:\n",
    "            ks_value = (df_ks.loc[(df_ks[\"scenario1\"] == scenario) &\n",
    "                                 (df_ks[\"variable\"] == variable) &\n",
    "                                 (df_ks[\"channel\"] == channel)][\"ks_stat\"]\n",
    "                        .values.tolist())\n",
    "            ks_lst.append(\"{}: {}\".format(scenario, ks_value[0]))\n",
    "    xt_dict = {\"FLOW\": [\"Flow\", \"CFS\"], \"VEL\": [\"Velocity\", \"FT/S\"]}\n",
    "    ks_stat = \"|\".join(ks_lst)\n",
    "    KS_annotation = [go.layout.Annotation(x=0, y=1.10,\n",
    "                                          xref=\"paper\",\n",
    "                                          yref=\"paper\",\n",
    "                                          showarrow=False,\n",
    "                                          text=\"Kolmogorov-Smirnov \" +\n",
    "                                          \"Distance: {}\"\n",
    "                                          .format(ks_stat),\n",
    "                                         font=dict(size=16))]\n",
    "    xt_var = xt_dict.get(variable)\n",
    "    xt = \"{} in {}\".format(xt_var[0], xt_var[1])\n",
    "    yt = \"Fraction of Data\"\n",
    "    layout = go.Layout(autosize=False, width=800, height=600,\n",
    "                       annotations=KS_annotation,\n",
    "                       legend=dict(font=dict(size=16)),\n",
    "                       legend_orientation=\"v\",\n",
    "                       xaxis=dict(title=dict(text=xt, font=dict(size=24))),\n",
    "                       yaxis=dict(title=dict(text=yt, font=dict(size=24))))\n",
    "    ecdf_fig = go.Figure(data=trace_lst,\n",
    "                         layout=layout)\n",
    "    return ecdf_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays sample visualizations of the mapgraph and the map for the user to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(build_mapgraph(\"FLOW\", 214))\n",
    "display(build_map(test_map_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a reactive panel variable for the graph objects in the *.html* Panel Visualization.  \n",
    "This effectively creates the graphs for each of the dropdown options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pn.depends(variable_dropdown, channel_dropdown)\n",
    "def reactive_graph(variable_dropdown, channel_dropdown):\n",
    "    return build_mapgraph(variable_dropdown, channel_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the panel tabs for each of the map objeccts in the *.html* Panel Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabs = pn.Tabs()\n",
    "for opt in map_ks_options:\n",
    "    map_obj = build_map(opt)\n",
    "    tabs.append((opt, map_obj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gspec is the Panel Builder object that becomes saved as the *.html* Panel Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gspec = pn.GridSpec(sizing_mode=\"stretch_both\", max_height=800, max_width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gspec[0:2, 0] = pn.Column(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gspec[0:2, 1] = pn.Column(pn.Row(variable_dropdown,\n",
    "                                 channel_dropdown),\n",
    "                          reactive_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gspec.save(panel_html_vis_output_pathname, embed=True, max_opts=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for writing out the extended graphs for input into reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeExtendGraphs(channel_lst, variable_lst, output_dir):\n",
    "    for v in variable_lst:\n",
    "        for c in channel_lst:\n",
    "            print(v, c)\n",
    "            fig = build_mapgraph(v, c)\n",
    "            output_pathname = os.path.join(output_dir, \"{}_{}_ecdf.png\".format(v, c))\n",
    "            pio.write_image(fig, output_pathname)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MakeExtendGraphs(channel_lst, variable_lst, graph_png_output_pathname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Additional Statistics and KS-Stat Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for building the additional statistic tables for min, max, mean, and percent positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeStatTable(vartotal_df, channels=channel_lst):\n",
    "    df = vartotal_df.copy()\n",
    "    df_channel = df.loc[(df.channel.isin(channels))]\n",
    "    grouper = df_channel.groupby([\"scenario\", \"variable\", \"channel\"])\n",
    "    df_describe = grouper.describe()\n",
    "    df_describe.columns = df_describe.columns.droplevel(0)\n",
    "    df_describe = df_describe.sort_index(level=[\"variable\", \"channel\"])\n",
    "    df_stats = df_describe[[\"min\", \"max\", \"mean\"]]\n",
    "    df_percent = grouper.apply(lambda x: ((x[\"value\"]>0).sum()\n",
    "                               / x[\"value\"].count())*100)\n",
    "    df_percent = df_percent.sort_index(level=[\"variable\", \"channel\"])\n",
    "    df_final = pd.concat([df_stats, df_percent], axis=1)\n",
    "    df_final = df_final.rename(columns={0: \"% positive\"})\n",
    "    df_final = df_final.round(2)\n",
    "    df_final = df_final.unstack(\"variable\")  \n",
    "    df_final = df_final.swaplevel(0, -1, axis=1)\n",
    "    df_final.columns.set_levels([\"Flow\", \"Velocity\"], level=0, inplace=True)\n",
    "    df_final.columns.set_levels([\"Minimum Flow\", \"Maximum Flow\", \"Mean Flow\", \"% Positive Flow\",\n",
    "                                 \"Minimum Velocity\", \"Maximum Velocity\", \"Mean Velocity\",\n",
    "                                 \"% Positive Velocity\"],level=1,inplace=True)\n",
    "    df_final = df_final.sort_index(axis=1, level=0, sort_remaining=False)\n",
    "    df_final = df_final.sort_index(axis=0, level=1, sort_remaining=False)\n",
    "    df_final.columns.names = (None, None)  \n",
    "    df_final.index.names = (None, \"DSM2 Channel\")\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Additional Statistic Tables for the channel_lst variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat = MakeStatTable(vartotal_df, channels=channel_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Additional Stastistic Tables for the critical_channel_lst variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cstat = MakeStatTable(vartotal_df,\n",
    "                         channels=critical_channel_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cstat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for building the additional KS-Stat tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKSTable(varks_df, channels=channel_lst):\n",
    "    df = varks_df.copy()\n",
    "    df_channels = df.loc[(df.channel.isin(channels))]\n",
    "    df_channels = df_channels.set_index([\"scenario0\", \"scenario1\",\n",
    "                                         \"variable\", \"channel\"])\n",
    "    df_ks = df_channels.unstack([\"scenario0\", \"scenario1\"])\n",
    "    df_ks = df_ks.sort_index(level=[\"variable\", \"channel\"])\n",
    "    df_ks.columns = df_ks.columns.droplevel(0)\n",
    "    df_ks = df_ks.unstack(\"variable\")\n",
    "    \n",
    "    df_ks = df_ks.swaplevel(0, -1, axis=1)\n",
    "    df_ks = df_ks.swaplevel(-1, 1, axis=1)\n",
    "\n",
    "    df_ks.columns.names = (None, None, None)\n",
    "    df_ks.index.names = [\"DSM2 Channel\"]\n",
    "    df_ks = df_ks.sort_index(axis=1, level=0, sort_remaining=False)\n",
    "    df_ks.columns.set_levels([\"Flow\", \"Velocity\"], level=0, inplace=True)\n",
    "    df_ks = df_ks.round(4)\n",
    "    return df_ks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create KS-Stat Tables for the channel_lst variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks = MakeKSTable(varks_df, channels=channel_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create KS-Stat Tables for the critical_channel_lst variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cks = MakeKSTable(varks_df, channels=critical_channel_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out the Additional Statistics and KS-Stat Tables to the tables_csv_output_pathname directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_write_dict = {'critical__statistics': df_cstat,\n",
    "                 'critical_ks': df_cks,\n",
    "                 'statistics': df_stat,\n",
    "                 'ks': df_ks}\n",
    "\n",
    "\n",
    "def WriteExtraTablesCSV(df_write_dict, output_dir):\n",
    "    for k, v in df_write_dict.items():\n",
    "        print(k)\n",
    "        pathname = os.path.join(output_dir, \"{}.csv\".format(k))\n",
    "        print(pathname)\n",
    "        v.to_csv(pathname, sep=',')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WriteExtraTablesCSV(df_write_dict, tables_csv_output_pathname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
